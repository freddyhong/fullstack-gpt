{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: \n",
      "I know this:\n",
      "Capital: Berlin\n",
      "Language: German\n",
      "Food: Bratwurst and Sauerkraut\n",
      "Currency: Euro"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='AI: \\nI know this:\\nCapital: Berlin\\nLanguage: German\\nFood: Bratwurst and Sauerkraut\\nCurrency: Euro')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature = 0.1,\n",
    "    streaming = True,\n",
    "    callbacks = [\n",
    "        StreamingStdOutCallbackHandler()\n",
    "    ],\n",
    ")\n",
    "\n",
    "# example of PromptTemplate\n",
    "\n",
    "'''\n",
    "t = PromptTemplate.from_template(\"What is the capital of {country}\")\n",
    "t.format(country = \"France\")\n",
    "\n",
    "'''\n",
    "# another way of using PromptTemplate\n",
    "''' \n",
    "t = PromptTemplate(\n",
    "    template = \"what is the capital of {country}\",\n",
    "    input_varibale = [\"country\"],\n",
    ")\n",
    "t.format(country = \"France\")\n",
    "'''\n",
    "\n",
    "\n",
    "# FewShotPromptTemplate\n",
    "\n",
    "examples = [\n",
    "{\n",
    "\"question\": \"What do you know about France?\",\n",
    "\"answer\": \"\"\"\n",
    "Here is what I know:\n",
    "Capital: Paris\n",
    "Language: French\n",
    "Food: Wine and Cheese\n",
    "Currency: Euro\n",
    "\"\"\",\n",
    "},\n",
    "{\n",
    "\"question\": \"What do you know about Italy?\",\n",
    "\"answer\": \"\"\"\n",
    "I know this:\n",
    "Capital: Rome\n",
    "Language: Italian\n",
    "Food: Pizza and Pasta\n",
    "Currency: Euro\n",
    "\"\"\",\n",
    "},\n",
    "{\n",
    "\"question\": \"What do you know about Greece?\",\n",
    "\"answer\": \"\"\"\n",
    "I know this:\n",
    "Capital: Athens\n",
    "Language: Greek\n",
    "Food: Souvlaki and Feta Cheese\n",
    "Currency: Euro\n",
    "\"\"\",\n",
    "},\n",
    "]\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(\"Human: {question} \\nAI: {answer}\") # \"question\" and \"answer\" should be same with the examples!\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt = example_prompt, \n",
    "    examples = examples,\n",
    "    suffix = \"Human: What do you know about {country}?\", # Our question\n",
    "    input_variables = [\"country\"]\n",
    ")\n",
    "\n",
    "prompt.format(country = \"Germany\")\n",
    "chain = prompt | chat\n",
    "\n",
    "chain.invoke({\n",
    "    \"country\" : \"Germany\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:50: SyntaxWarning: 'tuple' object is not callable; perhaps you missed a comma?\n",
      "<>:50: SyntaxWarning: 'tuple' object is not callable; perhaps you missed a comma?\n",
      "/var/folders/sd/r4jvnq1n6hl4kqn9gl73zfqr0000gn/T/ipykernel_98705/4259065158.py:50: SyntaxWarning: 'tuple' object is not callable; perhaps you missed a comma?\n",
      "  (\"human\", \"What do you know about {country}?\")\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 50\u001b[0m\n\u001b[1;32m      6\u001b[0m chat \u001b[38;5;241m=\u001b[39m ChatOpenAI(\n\u001b[1;32m      7\u001b[0m     temperature \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m      8\u001b[0m     streaming \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     ],\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m examples \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     15\u001b[0m {\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcountry\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrance?\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m },\n\u001b[1;32m     45\u001b[0m ]\n\u001b[1;32m     49\u001b[0m example_prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages([\n\u001b[0;32m---> 50\u001b[0m     \u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhuman\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat do you know about \u001b[39;49m\u001b[38;5;132;43;01m{country}\u001b[39;49;00m\u001b[38;5;124;43m?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mai\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{answer}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m ])\n\u001b[1;32m     54\u001b[0m example_prompt \u001b[38;5;241m=\u001b[39m FewShotChatMessagePromptTemplate(\n\u001b[1;32m     55\u001b[0m     example_prompt \u001b[38;5;241m=\u001b[39m example_prompt, \n\u001b[1;32m     56\u001b[0m     examples \u001b[38;5;241m=\u001b[39m examples,\n\u001b[1;32m     57\u001b[0m )\n\u001b[1;32m     59\u001b[0m final_prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages([\n\u001b[1;32m     60\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a geography expert, you give short answers.\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     61\u001b[0m     example_prompt,\n\u001b[1;32m     62\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat do you know about \u001b[39m\u001b[38;5;132;01m{country}\u001b[39;00m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     63\u001b[0m ])\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature = 0.1,\n",
    "    streaming = True,\n",
    "    callbacks = [\n",
    "        StreamingStdOutCallbackHandler()\n",
    "    ],\n",
    ")\n",
    "\n",
    "examples = [\n",
    "{\n",
    "\"country\": \"France?\",\n",
    "\"answer\": \"\"\"\n",
    "Here is what I know:\n",
    "Capital: Paris\n",
    "Language: French\n",
    "Food: Wine and Cheese\n",
    "Currency: Euro\n",
    "\"\"\",\n",
    "},\n",
    "{\n",
    "\"country\": \"Italy?\",\n",
    "\"answer\": \"\"\"\n",
    "I know this:\n",
    "Capital: Rome\n",
    "Language: Italian\n",
    "Food: Pizza and Pasta\n",
    "Currency: Euro\n",
    "\"\"\",\n",
    "},\n",
    "{\n",
    "\"country\": \"Greece?\",\n",
    "\"answer\": \"\"\"\n",
    "I know this:\n",
    "Capital: Athens\n",
    "Language: Greek\n",
    "Food: Souvlaki and Feta Cheese\n",
    "Currency: Euro\n",
    "\"\"\",\n",
    "},\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"What do you know about {country}?\")\n",
    "    (\"ai\", \"{answer}\")\n",
    "])\n",
    "\n",
    "example_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt = example_prompt, \n",
    "    examples = examples,\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a geography expert, you give short answers.\"),\n",
    "    example_prompt,\n",
    "    (\"human\", \"What do you know about {country}?\")\n",
    "])\n",
    "\n",
    "chain = final_prompt | chat\n",
    "\n",
    "chain.invoke({\n",
    "    \"country\" : \"Germany\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature = 0.1,\n",
    "    streaming = True,\n",
    "    callbacks = [\n",
    "        StreamingStdOutCallbackHandler()\n",
    "    ],\n",
    ")\n",
    "\n",
    "# example of PromptTemplate\n",
    "\n",
    "'''\n",
    "t = PromptTemplate.from_template(\"What is the capital of {country}\")\n",
    "t.format(country = \"France\")\n",
    "\n",
    "'''\n",
    "# another way of using PromptTemplate\n",
    "''' \n",
    "t = PromptTemplate(\n",
    "    template = \"what is the capital of {country}\",\n",
    "    input_varibale = [\"country\"],\n",
    ")\n",
    "t.format(country = \"France\")\n",
    "'''\n",
    "\n",
    "\n",
    "# FewShotPromptTemplate\n",
    "\n",
    "examples = [\n",
    "{\n",
    "\"question\": \"What do you know about France?\",\n",
    "\"answer\": \"\"\"\n",
    "Here is what I know:\n",
    "Capital: Paris\n",
    "Language: French\n",
    "Food: Wine and Cheese\n",
    "Currency: Euro\n",
    "\"\"\",\n",
    "},\n",
    "{\n",
    "\"question\": \"What do you know about Italy?\",\n",
    "\"answer\": \"\"\"\n",
    "I know this:\n",
    "Capital: Rome\n",
    "Language: Italian\n",
    "Food: Pizza and Pasta\n",
    "Currency: Euro\n",
    "\"\"\",\n",
    "},\n",
    "{\n",
    "\"question\": \"What do you know about Greece?\",\n",
    "\"answer\": \"\"\"\n",
    "I know this:\n",
    "Capital: Athens\n",
    "Language: Greek\n",
    "Food: Souvlaki and Feta Cheese\n",
    "Currency: Euro\n",
    "\"\"\",\n",
    "},\n",
    "]\n",
    "\n",
    "# Example of RandomExampleSelector\n",
    "\n",
    "class RandomExampleSelector(BaseExampleSelector):\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "    \n",
    "    def add_example(self, example):\n",
    "        self.examples.append(example)\n",
    "\n",
    "    def select_examples(self, input_variables):\n",
    "        from random import choice \n",
    "        return [choice(self.examples)]\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(\"Human: {question} \\nAI: {answer}\") # \"question\" and \"answer\" should be same with the examples!\n",
    "\n",
    "# Example of LengthBasedExampleSelector\n",
    " \n",
    "\"\"\"\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=80 # how many examples I am going to use\n",
    ")\n",
    "\"\"\"\n",
    "example_selector = RandomExampleSelector(\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt = example_prompt, \n",
    "    example_selector=example_selector,\n",
    "    suffix = \"Human: What do you know about {country}?\", # Our question\n",
    "    input_variables = [\"country\"]\n",
    ")\n",
    "\n",
    "prompt.format(country = \"Germany\")\n",
    "chain = prompt | chat\n",
    "\n",
    "chain.invoke({\n",
    "    \"country\" : \"Germany\"\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
